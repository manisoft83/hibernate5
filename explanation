Generated Value
	AUTO
	Identity
	Sequence
	Table - Not supported in MySQl
	
CasCade Entity
Delete Orphan
Association
	Many to One
	One to Many
	Join Table

Dirty Read
Phantom Read
Unrepeatable read

Fetching strategies
	Run dataloader under com.sample.demo.fetch.select.DataLoader.java to load data before running each Data*Fetch.java
		
	Fetch(FetchMode.SELECT)
		Hibernate generates multiple select statements (one for parent and another one for child) 
			1. Select statement to retrieve the Stock records –session.get(Stock.class, 114)
			2. Select its related collections – sets.iterator()
	@Fetch(FetchMode.JOIN)
		 1. Select statement to retrieve the Stock records and outer join its related collections.
		 2. sample
		 	 from stock stock0_ left outer join	stock_daily_record stockdaily1_	on stock0_.STOCK_ID=stockdaily1_.STOCK_ID  where  stock0_.STOCK_ID=?\
	@BatchSize(size = 10)
		1. Select statement to retrieve all the Stock records.
		2. Select In statement to per-fetch its related collections (10 collections a time)
		3. Select In statement to per-fetch its related collections (next 10 collections a time)
	@Fetch(FetchMode.SUBSELECT)
		With “subselect” enabled, it will create two select statements.
		1. Select statement to retrieve all the Stock records.
		2. Select all its related collections in a sub select query.
Inheritance
	Table Per Concrete Class
	Table Per Hierarchy
	Table Per Sub Class
	
Table Per Hierarchy
	CREATE TABLE `employee_perhierarchy` (
	  `type` varchar(31) NOT NULL,
	  `id` int(11) NOT NULL,
	  `name` varchar(255) DEFAULT NULL,
	  `bonus` int(11) DEFAULT NULL,
	  `salary` float DEFAULT NULL,
	  `contract_duration` varchar(255) DEFAULT NULL,
	  `pay_per_hour` float DEFAULT NULL,
	  PRIMARY KEY (`id`)
	) ENGINE=MyISAM DEFAULT CHARSET=latin1;
	

Table Per Concrete Class
		CREATE TABLE `employee_tableperconcrete` (
		  `id` int(11) NOT NULL,
		  `name` varchar(255) DEFAULT NULL,
		  PRIMARY KEY (`id`)
		) ENGINE=MyISAM DEFAULT CHARSET=latin1;
		
		CREATE TABLE `regularemployee_tableperconcrete` (
		  `id` int(11) NOT NULL,
		  `name` varchar(255) DEFAULT NULL,
		  `bonus` int(11) DEFAULT NULL,
		  `salary` float DEFAULT NULL,
		  PRIMARY KEY (`id`)
		) ENGINE=MyISAM DEFAULT CHARSET=latin1;
		
		CREATE TABLE `contractemployee_tableperconcrete` (
		  `id` int(11) NOT NULL,
		  `name` varchar(255) DEFAULT NULL,
		  `contract_duration` varchar(255) DEFAULT NULL,
		  `pay_per_hour` float DEFAULT NULL,
		  PRIMARY KEY (`id`)
		) ENGINE=MyISAM DEFAULT CHARSET=latin1
	
Table Per Sub Class
	CREATE TABLE `employee_tablepersubclass` (
	  `id` int(11) NOT NULL,
	  `name` varchar(255) DEFAULT NULL,
	  PRIMARY KEY (`id`)
	) ENGINE=MyISAM DEFAULT CHARSET=latin1;
	
	CREATE TABLE `contractemployee_tablepersubclass` (
	  `contract_duration` varchar(255) DEFAULT NULL,
	  `pay_per_hour` float DEFAULT NULL,
	  
	  `ID` int(11) NOT NULL,
	  PRIMARY KEY (`ID`)
	) ENGINE=MyISAM DEFAULT CHARSET=latin1;
	
	CREATE TABLE `regularemployee_tablepersubclass` (
	  `bonus` int(11) DEFAULT NULL,
	  `salary` float DEFAULT NULL,
	  
	  `ID` int(11) NOT NULL,
	  PRIMARY KEY (`ID`)
	) ENGINE=MyISAM DEFAULT CHARSET=latin1;
	 
1) Difference between HQL and Criteria Query in Hibernate
*HQL is to perform both select and non-select operations on the data,  but Criteria is only for selecting the data, we cannot perform non-select operations using criteria
*HQL is suitable for executing Static Queries, where as Criteria is suitable for executing Dynamic Queries
*HQL doesn’t support pagination concept, but we can achieve pagination with Criteria
*Criteria used to take more time to execute then HQL
*With Criteria we are safe with SQL Injection because of its dynamic query generation but in HQL as your queries are either fixed or parametrized, there is no safe from SQL Injection.


2) Difference Between Hibernate Save And Persist Methods
If our generator class is assigned, then there is no difference between save() and persist() methods. Because generator ‘assigned’ means, as  a programmer we need to give the primary key value to save in the database right [ Hope you know this generators concept ]

In case of other than assigned generator class, suppose if our generator class name is Increment means hibernate it self will assign the primary key id value into the database right [ other than assigned generator, hibernate only used to take care the primary key id value remember :-) ], so in this case if we call save() or persist() method then it will insert the record into the database normally

But here thing is,  save() method can return that primary key id value which is generated by hibernate and we can see it by
	long s = session.save(k);
In this same case, persist() will never give any value back to the client, hope you are clear.

3) Difference between HQL and Criteria Query in Hibernate
*HQL is to perform both select and non-select operations on the data,  but Criteria is only for selecting the data, we cannot perform non-select operations using criteria
*HQL is suitable for executing Static Queries, where as Criteria is suitable for executing Dynamic Queries
*HQL doesn’t support pagination concept, but we can achieve pagination with Criteria
*Criteria used to take more time to execute then HQL
*With Criteria we are safe with SQL Injection because of its dynamic query generation but in HQL as your queries are either fixed or parametrized, there is no safe from SQL Injection.

In theory, named queries have less overhead than Criteria.
SQL-generation overhead we have:
*	Named HQL/JPAQL Query - SQL generation happens only once.
*	Criteria - No need to parse before generating.
*	(non-named) HQL/JPAQL Query - Parse, then generate.

	
I'm the guy who wrote the Hibernate 3 query translator back in 2004, so I know something about how it works.

Criteria, in theory should have less overhead than an HQL query (except for named queries, which I'll get to). This is because Criteria doesn't need to parse anything. HQL queries are parsed with an ANTLR-based parser and then the resulting AST is turned into SQL. However, with HQL/JPAQL you can define named queries, where the SQL is generated when the SessionFactory starts up. In theory, named queries have less overhead than Criteria.

So, in terms of SQL-generation overhead we have:
	-Named HQL/JPAQL Query - SQL generation happens only once.
	-Criteria - No need to parse before generating.
	-(non-named) HQL/JPAQL Query - Parse, then generate.
That said, choosing a query technique based on the overhead of parsing and SQL generation is probably a mistake in my opinion. 
This overhead is typically very small when compared to performing a real query on a real database server with real data. 


Here are the things I consider when deciding between Criteria and HQL/JPAQL:
	-First, you have to decide if you're OK with having a dependency on Hibernate-proprietary API in your code. JPA doesn't have Criteria.
	-Criteria is really good at handling many optional search parameters such as you might find on a typical web page with a multi-parameter 'search form'. With HQL, developers tend to tack on where clause expressions with StringBuilder (avoid this!). With Criteria, you don't need to do that. Hardik posted similar opinions.
	-HQL/JPAQL can be used for most other things, because the code tends to be smaller and easier for developers to understand.
	-Really frequent queries can be turned into named queries if you use HQL. I prefer to do this later, after some profiling.

4) If mutable = “false” or @Immutable is declared in collection, it means the add and delete-orphan are not allow in this collection, 
  		with exception throw, only update and ‘cascade delete all’ are allow.
  		
  		
Lost Updates – one transaction (T1) updates the data and commits successfully where as the second transaction (T2) fails to commit. In this case updates done by transaction (T1) are lost. This can be the situation when concurrent transactions are not isolated.
Dirty Read (Read Uncommitted Data) -  One transaction (T1) reads the uncommitted data (updates are done, but not committed) by another transaction (T2).
Phantom Read-  Transaction (T1) executes same query twice and the result sets is different each time, probably because another transaction (T2) has either added or deleted the records.
Unrepeatable Read- Transaction (T1) reads the same row twice and state of row is different probably because another transaction (T2) updates the row. Special case would be if T1 updates and committed the same data again, then updates done by T2 will be lost.

JTA Transaction Isolation Levels

Read Uncommitted- One transaction can view uncommitted data of another transaction and dirty read, phantom read, unrepeatable reads are allowed. This is the loosest isolation level and is not recommended. 
Read Committed – Dirty Reads (Uncommitted Read) are not allowed in this isolation level, but unrepeatable reads and phantom reads are permitted. This approach uses shared read lock and exclusive write lock in which read lock is acquired and released immediately where as write lock is released at the end of the transaction.
Repeatable Read-  Dirty Read and Unrepeatable Read is not allowed in this isolation level but phantom reads are allowed. In this isolation level, reading transaction will block all other writing transactions ( but allows other reading transactions ) and any writing transaction will block all other transactions. This will have some scalability issues.
Serializable- This is the strictest isolation level and will have  scalability issues. This prevents dirty read, phantom reads , unrepeatable read etc. Transactions are executed serially (one after another) and acquires read and write locks on the entire set of affected data.

Isolation Level		Phantom Read	Unrepeatable Read		Dirty Read
Read Uncommitted	Allowed			Allowed					Allowed
Read Committed		Allowed			Allowed					Not Allowed
Repeatable Read		Allowed			Not Allowed				Not Allowed
Serializable		Not allowed		Not allowed				Not allowed

 
EHCache - Pitfall

Pitfall 1 - Query cache worsens performance causing a high volume of queries
There is an harmful side-effect of how the two caches work, that occurs if the cached query results are configured to expire more frequently than the cached entities returned by the query.

If a query has cached results, it returns a list of entity Id's, that is then resolved against the second level cache. If the entities with those Ids where not configured as cacheable or if they have expired, then a select will hit the database per entity Id.

For example if a cached query returned 1000 entity Ids, and non of those entities where cached in the second level cache, then 1000 selects by Id will be issued against the database.

The solution to this problem is to configure query results expiration to be aligned with the expiration of the entities returned by the query.

Pitfall 2 - Cache limitations when used in conjunction with @Inheritance
It is currently not possible to specify different caching policies for different subclasses of the same parent entity.

Pitfall 3 - Cache settings get ignored when using a singleton based cache
It is advised to configure the cache region factory as a EhCacheRegionFactory, and specify an ehcache configuration via net.sf.ehcache.configurationResourceName.

There is an alternative to this region factory which is SingletonEhCacheRegionFactory. With this region factory the cache regions are stored in a singleton using the cache name as a lookup key.

The problem with the singleton region factory is that if another part of the application had already registered a cache with the default name in the singleton, this causes the ehcache configuration file passed via net.sf.ehcache.configurationResourceName to be ignored.

